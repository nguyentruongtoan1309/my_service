{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\toan\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (1.19.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\toan\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (1.2.1)\n",
      "Requirement already satisfied: sklearn in c:\\users\\toan\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: nltk in c:\\users\\toan\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (3.5)\n",
      "Requirement already satisfied: pyvi in c:\\users\\toan\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (0.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\toan\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (2.5)\n",
      "Requirement already satisfied: gensim in c:\\users\\toan\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (3.8.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\toan\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (0.17.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\toan\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (from gensim) (3.0.0)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\toan\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (from gensim) (1.5.4)\n",
      "Requirement already satisfied: six>=1.5.0 in c:\\users\\toan\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (from gensim) (1.15.0)\n",
      "Requirement already satisfied: Cython==0.29.14 in c:\\users\\toan\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (from gensim) (0.29.14)\n",
      "Requirement already satisfied: requests in c:\\users\\toan\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (from smart-open>=1.8.1->gensim) (2.24.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\toan\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (from networkx) (4.4.2)\n",
      "Requirement already satisfied: click in c:\\users\\toan\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\toan\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (from nltk) (4.51.0)\n",
      "Requirement already satisfied: regex in c:\\users\\toan\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (from nltk) (2020.10.28)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\toan\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (from pandas) (2020.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\toan\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: sklearn-crfsuite in c:\\users\\toan\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (from pyvi) (0.3.6)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\toan\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (from pyvi) (0.23.2)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\toan\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (from requests->smart-open>=1.8.1->gensim) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\toan\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (from requests->smart-open>=1.8.1->gensim) (2020.11.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\toan\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (from requests->smart-open>=1.8.1->gensim) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\toan\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (from requests->smart-open>=1.8.1->gensim) (1.25.11)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\toan\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (from scikit-learn->pyvi) (2.1.0)\n",
      "Requirement already satisfied: python-crfsuite>=0.8.3 in c:\\users\\toan\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (from sklearn-crfsuite->pyvi) (0.9.7)\n",
      "Requirement already satisfied: tabulate in c:\\users\\toan\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (from sklearn-crfsuite->pyvi) (0.8.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy pandas sklearn nltk pyvi networkx gensim joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\toan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('punkt') # one time execution\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read file contain stopwords\n",
    "def read_vi_stopwords(file_name):\n",
    "  file = open(file_name, encoding=\"utf8\")\n",
    "  filedata = file.read()\n",
    "  stop_words=[]\n",
    "  stop_words = [stopword.rstrip('\\n') for stopword in open(file_name, encoding=\"utf8\")]\n",
    "  return stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# function to remove stopwords\n",
    "stop_words=read_vi_stopwords(r'C:\\Users\\toan\\Desktop\\KHOA LUAN\\Sprint 10\\vietnamese-stopwords.txt')\n",
    "def remove_stopwords(sen):\n",
    "  sen_new = \" \".join([i for i in sen if i not in stop_words])\n",
    "  return sen_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embeddings = {}\n",
    "f = open(r'C:\\Users\\toan\\Desktop\\KHOA LUAN\\Sprint 10\\vi.txt', encoding='utf-8')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    word_embeddings[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textRank(content):\n",
    "    contents_parsed = content.lower() #Biến đổi hết thành chữ thường\n",
    "    contents_parsed = contents_parsed.replace('.\\n', '. ')\n",
    "    contents_parsed = contents_parsed.replace('\\n', '. ') # Đổi các ký tự xuống dòng thành chấm câu \n",
    "    contents_parsed = contents_parsed.strip() #Loại bỏ đi các khoảng trắng thừa\n",
    "    import nltk\n",
    "    nltk.download('punkt')\n",
    "    origin_sentences = nltk.sent_tokenize(contents_parsed)\n",
    "    sentences_without_sw = [remove_stopwords(r.split()) for r in origin_sentences]\n",
    "    sentence_vectors = []\n",
    "    for i in sentences_without_sw:\n",
    "      if len(i) != 0:\n",
    "        v = sum([word_embeddings.get(w, np.zeros((100,))) for w in i.split()])/(len(i.split())+0.001)\n",
    "      else:\n",
    "        v = np.zeros((100,))\n",
    "      sentence_vectors.append(v)\n",
    "    # similarity matrix\n",
    "    sim_mat = np.zeros([len(sentences_without_sw), len(sentences_without_sw)])\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "    # khởi tạo ma trận với điểm số tương tự cosine.\n",
    "    for i in range(len(sentences_without_sw)):\n",
    "      for j in range(len(sentences_without_sw)):\n",
    "        if i != j:\n",
    "          sim_mat[i][j] = cosine_similarity(sentence_vectors[i].reshape(1,100), sentence_vectors[j].reshape(1,100))[0,0]\n",
    "    # chuyển đổi ma trận tương tự sim_mat thành một đồ thị\n",
    "    import networkx as nx\n",
    "    nx_graph = nx.from_numpy_array(sim_mat)\n",
    "    # áp dụng thuật toán Xếp hạng trang để xếp hạng câu\n",
    "    scores = nx.pagerank(nx_graph)\n",
    "    import heapq\n",
    "    top_sentences = heapq.nlargest(2, scores, key=scores.get)\n",
    "    summary=''\n",
    "    for i in top_sentences:\n",
    "      summary+=origin_sentences[i]\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./textRank.joblib']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(word_embeddings, \"./word_embeddings.joblib\", compress=True)\n",
    "joblib.dump(textRank, \"./textRank.joblib\", compress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
